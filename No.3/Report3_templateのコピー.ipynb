{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3回レポート課題\n",
    "\n",
    "学籍番号：XX-YYY\n",
    "氏名：ZZZZ ZZZZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10という画像データセットに対して、50000枚の学習用画像を用いて独自のニューラルネットワークを学習し、学習したニューラルネットワークを10000枚のテスト用画像に適用して、その結果を報告せよ。<font color=\"red\">特に、下記の点に従って、本レポートを作成すること。\n",
    "    \n",
    "- 下記に指定されたフォーマットで、ニューラルネットワークの学習・テスト用コードを実装すること\n",
    "\n",
    "\n",
    "- 下記に指定されたフォーマットで各処理を数学的に記述すること\n",
    "\n",
    "</font>\n",
    "\n",
    "なお、CIFAR10の詳細情報に関しては、下記の公式ページを参照するか、もしくはその他多くのWebページを調べれば分かる。\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの読み込みと説明\n",
    "\n",
    "### 下記の要領で、4つのnumpyデータを読み込め。（5点）\n",
    "\n",
    "- `train_data.npy`：50000枚の学習用画像が格納されている本データを読み込み、`x_train`という変数に格納せよ。各画像は、サイズが縦32ピクセル、横32ピクセルで、3チャンネルのRGBデータである。<font color=\"red\">特に、`x_train`は、行数が50000、列数が3072の行列（numpy array）とする。</font>行数は学習用画像の数で明らかであるが、列数は「RGBの3つの値で表された32$\\times$32個のピクセル」を **1行に整形**することによる（つまり、$3072 = 32 \\times 32 \\times 3$）。\n",
    "\n",
    "\n",
    "- `train_labels.npy`：50000枚の学習用画像のラベルが格納されいる本データを読み込み、`y_train`という変数に格納せよ。<font color=\"red\">特に、`y_train`は、行数が50000、列数が1の行列（numpy array）とする。</font>つまり、各行が、各学習用画像が属するクラスのIDを表している。\n",
    "\n",
    "\n",
    "- `test_data.npy`：10000枚のテスト用画像が格納されている本データを読み込み、`x_test`という変数に格納せよ。学習用画像と同様、各画像は、サイズが32x32で、3チャンネルのRGBデータである。<font color=\"red\">上述の`x_train`と同様の仕様に従い、`x_test`は、行数が10000、列数が3072の行列（numpy array）とする。</font>\n",
    "\n",
    "\n",
    "- `test_labels.npy`：10000枚のテスト用画像のラベルが格納されている本データを読み込み、`y_test`という変数に格納せよ。<font color=\"red\">上述の`y_train`と同様の仕様に従い、`y_test`は、行数が10000、列数が1の行列（numpy array）とする。</font>\n",
    "\n",
    "\n",
    "<font color=\"blue\">「どの画像が学習用で、どの画像がテスト用か」という学習用画像とテスト用画像の分割は、絶対に変更しないこと！ 変更した場合は、大幅に減点する。</font>また、データを読み込んだ後で、以降のニューラルネットワークの学習、テストで必要な**データの正規化**を行ってもらって構わない。この正規化は採点外である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コードを記述するセル\n",
    "import numpy as np\n",
    "\n",
    "# np.reshapeで50000x3072のnumpy arrayに変更.\n",
    "x_train = np.reshape(np.load('train_data.npy'), (50000, 3072))\n",
    "\n",
    "# np.reshapeで50000x1のnumpy arrayに変更.\n",
    "y_train = np.reshape(np.load('train_labels.npy'), (50000, 1))\n",
    "\n",
    "# np.reshapeで10000x3072のnumpy arrayに変更.\n",
    "x_test = np.reshape(np.load('test_data.npy'), (10000, 3072))\n",
    "\n",
    "# np.reshapeで10000x1のnumpy arrayに変更.\n",
    "y_test = np.reshape(np.load('test_labels.npy'), (10000, 1))\n",
    "\n",
    "# 以下正規化\n",
    "x_train = x_train.astype('float32') # float32型に変換\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 # RGB値を[0,255]から[0.0,1.0へ]\n",
    "x_test /= 255\n",
    "\n",
    "import keras\n",
    "\n",
    "# 今回の場合ではIDが10個あるので, 1の場合なら[1,0,0,0,0,0,0,0,0,0]\n",
    "# 2なら[0,1,0,0,0,0,0,0,0,0]という風に表している.\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# 以下, 確認用\n",
    "# print(x_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記で読み込んだデータのうち、$P=50000$個の学習用画像を$\\left\\{ (\\mathbf{x}_p, y_p) \\right\\}_{p=1}^{P}$としたとき、$\\mathbf{x}_p$と$y_p$が、何を表しているか**数学的に**説明せよ。（5点）\n",
    "\n",
    "つまり、\n",
    "\n",
    "- $\\mathbf{x}_p$は、$p$番目の学習用画像の特徴をどのように表現しているベクトルか\n",
    "\n",
    "\n",
    "- $y_p$は、$p$番目の学習用画像のラベルをどのように表現しているか\n",
    "\n",
    "について説明せよ。詳細な説明は不要で、$\\mathbf{x}_p$、$y_p$をそれぞれ、1, 2文で**簡潔かつ直感的に**説明することが望ましい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{x}_p$は$p$番目の学習用画像の色の並びを1行で表しており, $y_p$は$p$番目の学習用画像のラベルを1行で表している."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学習するモデルの実装と説明\n",
    "\n",
    "### `x_train`と`y_train`を用いて学習する複数の層からなるニューラルネットワークを実装せよ。（5点）\n",
    "\n",
    "層数、ユニット数、活性化関数などのニューラルネットワークの構造は、各自の任意とする。また、自分でニューラルネットワークを実装するのではなく、kerasというディープラーニングライブラリを用いることをお勧めする。kerasのインストール方法に関しては、下記を参照するとよい。\n",
    "\n",
    "https://www.info.kindai.ac.jp/~shirahama/courses/ml/2018/slides/installation_guide_mac.pdf\n",
    "\n",
    "もちろん、自分で実装したり、keras以外の別のライブラリを使用してもらっても構わない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # ②\n",
    "from sklearn.neural_network import MLPClassifier # ③ ④ ⑤\n",
    "from sklearn.metrics import accuracy_score, \\\n",
    "    classification_report, confusion_matrix # ⑥\n",
    "import pickle  # (A)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import Normalizer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記で実装したニューラルネットワークを**数学的に**説明せよ。（5点）\n",
    "\n",
    "つまり、それぞれの層の各ユニットで、どのような計算が行われているのか式で示せ。ただし、以下の点に留意すること。\n",
    "\n",
    "- <font color=\"red\">1層目のユニットの入力は、$\\mathbf{x}_p$とする。</font>\n",
    "\n",
    "\n",
    "- 1層目のユニットの入力以外は、自由に記号を定義してもらって構わない。ただし、定義した記号は、必ず説明すること。\n",
    "\n",
    "\n",
    "- 式で記述する層は、入力層、基底関数の層（全結合層）、活性化関数の層、出力層だけでよい。授業では解説していないDropout、バッチ正規化などの層を用いる場合は、それらの層の概念的な説明のみでよい。\n",
    "\n",
    "\n",
    "- 例えば、同じような基底関数の層を複数使用したとすると、同じような計算を繰り返して書く必要が出てくる。その場合は、例えば「この層のユニットの計算はX層目と同様」というように省略してもらって構わない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力層\n",
    "\n",
    "# 基底関数の層\n",
    "\n",
    "# 活性化関数の層\n",
    "\n",
    "# 出力層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習プロセスの実装と説明\n",
    "\n",
    "### `x_train`、`y_train`を用いて、上記で定義したニューラルネットワークを学習するコードを実装せよ。（5点）\n",
    "\n",
    "kerasなどのディープラーニングライブラリを用いれば、数行で書けると思われる。もちろん、自分で学習用のコードを実装しても構わないが、かなり長いコードになるはずなのでお勧めはしない。\n",
    "\n",
    "また、学習の設定（例えば、オプティマイザー、エポック数、バッチサイズなど）をコメントとして記述すること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,103,818\n",
      "Trainable params: 2,103,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 1.9377 - accuracy: 0.2943 - val_loss: 1.7476 - val_accuracy: 0.3651\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 1.7454 - accuracy: 0.3696 - val_loss: 1.6360 - val_accuracy: 0.4169\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 1.6712 - accuracy: 0.4038 - val_loss: 1.5624 - val_accuracy: 0.4459\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 1.6130 - accuracy: 0.4218 - val_loss: 1.5257 - val_accuracy: 0.4542\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.5697 - accuracy: 0.4374 - val_loss: 1.5017 - val_accuracy: 0.4635\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.5376 - accuracy: 0.4506 - val_loss: 1.4851 - val_accuracy: 0.4645\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 14s 284us/step - loss: 1.5010 - accuracy: 0.4633 - val_loss: 1.4429 - val_accuracy: 0.4819\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.4802 - accuracy: 0.4713 - val_loss: 1.4299 - val_accuracy: 0.4896\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 1.4527 - accuracy: 0.4790 - val_loss: 1.4139 - val_accuracy: 0.4920\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 15s 298us/step - loss: 1.4301 - accuracy: 0.4886 - val_loss: 1.3863 - val_accuracy: 0.5053\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 15s 301us/step - loss: 1.4042 - accuracy: 0.4956 - val_loss: 1.3953 - val_accuracy: 0.4975\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.3874 - accuracy: 0.5046 - val_loss: 1.3676 - val_accuracy: 0.5063\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.3705 - accuracy: 0.5080 - val_loss: 1.3620 - val_accuracy: 0.5173\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.3553 - accuracy: 0.5147 - val_loss: 1.3737 - val_accuracy: 0.5106\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 14s 282us/step - loss: 1.3376 - accuracy: 0.5229 - val_loss: 1.3721 - val_accuracy: 0.5103\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 14s 290us/step - loss: 1.3219 - accuracy: 0.5276 - val_loss: 1.3483 - val_accuracy: 0.5148\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.3098 - accuracy: 0.5283 - val_loss: 1.3328 - val_accuracy: 0.5237\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.2928 - accuracy: 0.5362 - val_loss: 1.3280 - val_accuracy: 0.5216\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.2764 - accuracy: 0.5423 - val_loss: 1.3298 - val_accuracy: 0.5264\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.2638 - accuracy: 0.5461 - val_loss: 1.3349 - val_accuracy: 0.5238\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.2530 - accuracy: 0.5526 - val_loss: 1.3193 - val_accuracy: 0.5243\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 14s 282us/step - loss: 1.2388 - accuracy: 0.5564 - val_loss: 1.3177 - val_accuracy: 0.5268\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 1.2290 - accuracy: 0.5607 - val_loss: 1.2939 - val_accuracy: 0.5404\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.2147 - accuracy: 0.5626 - val_loss: 1.3014 - val_accuracy: 0.5358\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.2078 - accuracy: 0.5670 - val_loss: 1.2865 - val_accuracy: 0.5381\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.1955 - accuracy: 0.5702 - val_loss: 1.3086 - val_accuracy: 0.5353\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.1865 - accuracy: 0.5741 - val_loss: 1.2933 - val_accuracy: 0.5385\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.1666 - accuracy: 0.5814 - val_loss: 1.2912 - val_accuracy: 0.5389\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 1.1628 - accuracy: 0.5828 - val_loss: 1.2739 - val_accuracy: 0.5440\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.1482 - accuracy: 0.5885 - val_loss: 1.2700 - val_accuracy: 0.5467\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のニューラルネットワークの学習で用いたコスト関数（損失関数）を数学的に説明せよ。（5点）\n",
    "\n",
    "以下の点に留意すること。\n",
    "\n",
    "- <font color=\"red\">上で定義した学習例の集合$\\left\\{ (\\mathbf{x}_p, y_p) \\right\\}_{p=1}^{P}$を用いること。</font>\n",
    "\n",
    "\n",
    "- 説明対象は、最上位層におけるコスト関数である。つまり、コスト関数は、$p$番目の学習用画像の特徴$\\mathbf{x}_p$に対するニューラルネットワークの出力（**自分で定義する**）と、$p$番目の学習用画像のラベル$y_p$を比較するはずである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（数学的説明を記述するセル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. テストプロセスの実装と説明\n",
    "\n",
    "### `x_test`と`y_test`を用いて学習したニューラルネットワークをテストするコードを実装せよ。（5点）\n",
    "\n",
    "特に、テスト結果として<font color=\"red\">精度（Accuracy）</font>を出力せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2700451587677002\n",
      "Test accuracy: 0.5467000007629395\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のテストにおける精度の計算方法を数学的に説明せよ。（5点）\n",
    "\n",
    "以下の点に留意すること。\n",
    "\n",
    "- <font color=\"red\">Q=10000個のテスト用画像$\\left\\{ (\\mathbf{x}_q, y_q) \\right\\}_{q=1}^{Q}$とすること\n",
    "    \n",
    "    \n",
    "- $q$番目のテスト用画像に対する学習済みのニューラルネットワークの出力（**自分で定義する**)と、$q$番目のテスト用画像のラベル$y_q$を比較するはずである。学習済みのニューラルネットワークの出力は、上記の学習プロセスで定義したものとよく似てくるはずである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（数学的説明を記述するセル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">特典：精度が高い上位5名は、10点加点する！</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
