{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3回レポート課題\n",
    "\n",
    "学籍番号：XX-YYY\n",
    "氏名：ZZZZ ZZZZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10という画像データセットに対して、50000枚の学習用画像を用いて独自のニューラルネットワークを学習し、学習したニューラルネットワークを10000枚のテスト用画像に適用して、その結果を報告せよ。<font color=\"red\">特に、下記の点に従って、本レポートを作成すること。\n",
    "    \n",
    "- 下記に指定されたフォーマットで、ニューラルネットワークの学習・テスト用コードを実装すること\n",
    "\n",
    "\n",
    "- 下記に指定されたフォーマットで各処理を数学的に記述すること\n",
    "\n",
    "</font>\n",
    "\n",
    "なお、CIFAR10の詳細情報に関しては、下記の公式ページを参照するか、もしくはその他多くのWebページを調べれば分かる。\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの読み込みと説明\n",
    "\n",
    "### 下記の要領で、4つのnumpyデータを読み込め。（5点）\n",
    "\n",
    "- `train_data.npy`：50000枚の学習用画像が格納されている本データを読み込み、`x_train`という変数に格納せよ。各画像は、サイズが縦32ピクセル、横32ピクセルで、3チャンネルのRGBデータである。<font color=\"red\">特に、`x_train`は、行数が50000、列数が3072の行列（numpy array）とする。</font>行数は学習用画像の数で明らかであるが、列数は「RGBの3つの値で表された32$\\times$32個のピクセル」を **1行に整形**することによる（つまり、$3072 = 32 \\times 32 \\times 3$）。\n",
    "\n",
    "\n",
    "- `train_labels.npy`：50000枚の学習用画像のラベルが格納されいる本データを読み込み、`y_train`という変数に格納せよ。<font color=\"red\">特に、`y_train`は、行数が50000、列数が1の行列（numpy array）とする。</font>つまり、各行が、各学習用画像が属するクラスのIDを表している。\n",
    "\n",
    "\n",
    "- `test_data.npy`：10000枚のテスト用画像が格納されている本データを読み込み、`x_test`という変数に格納せよ。学習用画像と同様、各画像は、サイズが32x32で、3チャンネルのRGBデータである。<font color=\"red\">上述の`x_train`と同様の仕様に従い、`x_test`は、行数が10000、列数が3072の行列（numpy array）とする。</font>\n",
    "\n",
    "\n",
    "- `test_labels.npy`：10000枚のテスト用画像のラベルが格納されている本データを読み込み、`y_test`という変数に格納せよ。<font color=\"red\">上述の`y_train`と同様の仕様に従い、`y_test`は、行数が10000、列数が1の行列（numpy array）とする。</font>\n",
    "\n",
    "\n",
    "<font color=\"blue\">「どの画像が学習用で、どの画像がテスト用か」という学習用画像とテスト用画像の分割は、絶対に変更しないこと！ 変更した場合は、大幅に減点する。</font>また、データを読み込んだ後で、以降のニューラルネットワークの学習、テストで必要な**データの正規化**を行ってもらって構わない。この正規化は採点外である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コードを記述するセル\n",
    "import numpy as np\n",
    "\n",
    "# np.reshapeで50000x3072のnumpy arrayに変更.\n",
    "x_train = np.reshape(np.load('train_data.npy'), (50000, 3072))\n",
    "\n",
    "# np.reshapeで50000x1のnumpy arrayに変更.\n",
    "y_train = np.reshape(np.load('train_labels.npy'), (50000, 1))\n",
    "\n",
    "# np.reshapeで10000x3072のnumpy arrayに変更.\n",
    "x_test = np.reshape(np.load('test_data.npy'), (10000, 3072))\n",
    "\n",
    "# np.reshapeで10000x1のnumpy arrayに変更.\n",
    "y_test = np.reshape(np.load('test_labels.npy'), (10000, 1))\n",
    "\n",
    "# 以下正規化\n",
    "x_train = x_train.astype('float32') # float32型に変換\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 # RGB値を[0,255]から[0.0,1.0へ]\n",
    "x_test /= 255\n",
    "\n",
    "import keras\n",
    "\n",
    "# 今回の場合ではIDが10個あるので, 1の場合なら[1,0,0,0,0,0,0,0,0,0]\n",
    "# 2なら[0,1,0,0,0,0,0,0,0,0]という風に表している.\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# 以下, 確認用\n",
    "# print(x_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記で読み込んだデータのうち、$P=50000$個の学習用画像を$\\left\\{ (\\mathbf{x}_p, y_p) \\right\\}_{p=1}^{P}$としたとき、$\\mathbf{x}_p$と$y_p$が、何を表しているか**数学的に**説明せよ。（5点）\n",
    "\n",
    "つまり、\n",
    "\n",
    "- $\\mathbf{x}_p$は、$p$番目の学習用画像の特徴をどのように表現しているベクトルか\n",
    "\n",
    "\n",
    "- $y_p$は、$p$番目の学習用画像のラベルをどのように表現しているか\n",
    "\n",
    "について説明せよ。詳細な説明は不要で、$\\mathbf{x}_p$、$y_p$をそれぞれ、1, 2文で**簡潔かつ直感的に**説明することが望ましい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{x}_p$は$p$番目の学習用画像の色の並びを1行で表しており, $y_p$は$p$番目の学習用画像のラベルを1行で表している."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 学習するモデルの実装と説明\n",
    "\n",
    "### `x_train`と`y_train`を用いて学習する複数の層からなるニューラルネットワークを実装せよ。（5点）\n",
    "\n",
    "層数、ユニット数、活性化関数などのニューラルネットワークの構造は、各自の任意とする。また、自分でニューラルネットワークを実装するのではなく、kerasというディープラーニングライブラリを用いることをお勧めする。kerasのインストール方法に関しては、下記を参照するとよい。\n",
    "\n",
    "https://www.info.kindai.ac.jp/~shirahama/courses/ml/2018/slides/installation_guide_mac.pdf\n",
    "\n",
    "もちろん、自分で実装したり、keras以外の別のライブラリを使用してもらっても構わない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# 学習のためのモデル\n",
    "model = Sequential()\n",
    "# 全結合層(3072層->512層)\n",
    "# 活性化関数(ReLu関数)\n",
    "model.add(Dense(512, activation='relu', input_dim=3072))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 活性化関数(softmax関数) \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記で実装したニューラルネットワークを**数学的に**説明せよ。（5点）\n",
    "\n",
    "つまり、それぞれの層の各ユニットで、どのような計算が行われているのか式で示せ。ただし、以下の点に留意すること。\n",
    "\n",
    "- <font color=\"red\">1層目のユニットの入力は、$\\mathbf{x}_p$とする。</font>\n",
    "\n",
    "\n",
    "- 1層目のユニットの入力以外は、自由に記号を定義してもらって構わない。ただし、定義した記号は、必ず説明すること。\n",
    "\n",
    "\n",
    "- 式で記述する層は、入力層、基底関数の層（全結合層）、活性化関数の層、出力層だけでよい。授業では解説していないDropout、バッチ正規化などの層を用いる場合は、それらの層の概念的な説明のみでよい。\n",
    "\n",
    "\n",
    "- 例えば、同じような基底関数の層を複数使用したとすると、同じような計算を繰り返して書く必要が出てくる。その場合は、例えば「この層のユニットの計算はX層目と同様」というように省略してもらって構わない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力層\n",
    "\n",
    "# 基底関数の層\n",
    "\n",
    "# 活性化関数の層\n",
    "\n",
    "# 出力層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習プロセスの実装と説明\n",
    "\n",
    "### `x_train`、`y_train`を用いて、上記で定義したニューラルネットワークを学習するコードを実装せよ。（5点）\n",
    "\n",
    "kerasなどのディープラーニングライブラリを用いれば、数行で書けると思われる。もちろん、自分で学習用のコードを実装しても構わないが、かなり長いコードになるはずなのでお勧めはしない。\n",
    "\n",
    "また、学習の設定（例えば、オプティマイザー、エポック数、バッチサイズなど）をコメントとして記述すること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,103,818\n",
      "Trainable params: 2,103,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 31s 624us/step - loss: 1.9549 - accuracy: 0.2833 - val_loss: 1.7709 - val_accuracy: 0.3648\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 28s 558us/step - loss: 1.8090 - accuracy: 0.3470 - val_loss: 1.6723 - val_accuracy: 0.3999\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 28s 565us/step - loss: 1.7440 - accuracy: 0.3704 - val_loss: 1.6204 - val_accuracy: 0.4302\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 29s 572us/step - loss: 1.6961 - accuracy: 0.3857 - val_loss: 1.6014 - val_accuracy: 0.4199\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 27s 536us/step - loss: 1.6546 - accuracy: 0.4033 - val_loss: 1.5799 - val_accuracy: 0.4329\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 30s 595us/step - loss: 1.6278 - accuracy: 0.4141 - val_loss: 1.5340 - val_accuracy: 0.4560\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 32s 649us/step - loss: 1.6034 - accuracy: 0.4243 - val_loss: 1.5418 - val_accuracy: 0.4492\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 25s 509us/step - loss: 1.5759 - accuracy: 0.4336 - val_loss: 1.5035 - val_accuracy: 0.4548\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 1.5631 - accuracy: 0.4366 - val_loss: 1.5018 - val_accuracy: 0.4680\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 28s 558us/step - loss: 1.5476 - accuracy: 0.4412 - val_loss: 1.4936 - val_accuracy: 0.4714\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 27s 532us/step - loss: 1.5247 - accuracy: 0.4496 - val_loss: 1.4549 - val_accuracy: 0.4842\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 1.5108 - accuracy: 0.4561 - val_loss: 1.4511 - val_accuracy: 0.4878\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 31s 611us/step - loss: 1.5034 - accuracy: 0.4620 - val_loss: 1.4406 - val_accuracy: 0.4877\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 27s 546us/step - loss: 1.4912 - accuracy: 0.4635 - val_loss: 1.4434 - val_accuracy: 0.4832\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 29s 589us/step - loss: 1.4737 - accuracy: 0.4704 - val_loss: 1.4369 - val_accuracy: 0.4843\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 30s 595us/step - loss: 1.4588 - accuracy: 0.4751 - val_loss: 1.4164 - val_accuracy: 0.4928\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 1.4523 - accuracy: 0.4777 - val_loss: 1.4193 - val_accuracy: 0.4905\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 1.4432 - accuracy: 0.4809 - val_loss: 1.4666 - val_accuracy: 0.4705\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 30s 600us/step - loss: 1.4276 - accuracy: 0.4848 - val_loss: 1.4176 - val_accuracy: 0.4934\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 32s 641us/step - loss: 1.4220 - accuracy: 0.4883 - val_loss: 1.3856 - val_accuracy: 0.5082\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 28s 565us/step - loss: 1.4119 - accuracy: 0.4932 - val_loss: 1.3971 - val_accuracy: 0.5029\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 29s 583us/step - loss: 1.4046 - accuracy: 0.4956 - val_loss: 1.3823 - val_accuracy: 0.5042\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 1.3939 - accuracy: 0.4983 - val_loss: 1.3981 - val_accuracy: 0.5007\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 29s 582us/step - loss: 1.3863 - accuracy: 0.5028 - val_loss: 1.3705 - val_accuracy: 0.5085\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 28s 551us/step - loss: 1.3759 - accuracy: 0.5026 - val_loss: 1.3636 - val_accuracy: 0.5110\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 25s 509us/step - loss: 1.3630 - accuracy: 0.5110 - val_loss: 1.3686 - val_accuracy: 0.5060\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 26s 522us/step - loss: 1.3593 - accuracy: 0.5113 - val_loss: 1.3618 - val_accuracy: 0.5092\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 27s 536us/step - loss: 1.3543 - accuracy: 0.5136 - val_loss: 1.3492 - val_accuracy: 0.5155\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 27s 531us/step - loss: 1.3495 - accuracy: 0.5163 - val_loss: 1.4120 - val_accuracy: 0.5031\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 29s 579us/step - loss: 1.3395 - accuracy: 0.5182 - val_loss: 1.3432 - val_accuracy: 0.5193\n"
     ]
    }
   ],
   "source": [
    "# from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.summary()\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=RMSprop(),\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,  # 画像とラベルデータ\n",
    "                    batch_size=64, # batch_sizeずつ学習\n",
    "                    epochs=30,     # エポック数の指定\n",
    "                    verbose=1,         # ログ出力の指定. 0だとログが出ない\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のニューラルネットワークの学習で用いたコスト関数（損失関数）を数学的に説明せよ。（5点）\n",
    "\n",
    "以下の点に留意すること。\n",
    "\n",
    "- <font color=\"red\">上で定義した学習例の集合$\\left\\{ (\\mathbf{x}_p, y_p) \\right\\}_{p=1}^{P}$を用いること。</font>\n",
    "\n",
    "\n",
    "- 説明対象は、最上位層におけるコスト関数である。つまり、コスト関数は、$p$番目の学習用画像の特徴$\\mathbf{x}_p$に対するニューラルネットワークの出力（**自分で定義する**）と、$p$番目の学習用画像のラベル$y_p$を比較するはずである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（数学的説明を記述するセル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. テストプロセスの実装と説明\n",
    "\n",
    "### `x_test`と`y_test`を用いて学習したニューラルネットワークをテストするコードを実装せよ。（5点）\n",
    "\n",
    "特に、テスト結果として<font color=\"red\">精度（Accuracy）</font>を出力せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.343220739173889\n",
      "Test accuracy: 0.5192999839782715\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上記のテストにおける精度の計算方法を数学的に説明せよ。（5点）\n",
    "\n",
    "以下の点に留意すること。\n",
    "\n",
    "- <font color=\"red\">Q=10000個のテスト用画像$\\left\\{ (\\mathbf{x}_q, y_q) \\right\\}_{q=1}^{Q}$とすること\n",
    "    \n",
    "    \n",
    "- $q$番目のテスト用画像に対する学習済みのニューラルネットワークの出力（**自分で定義する**)と、$q$番目のテスト用画像のラベル$y_q$を比較するはずである。学習済みのニューラルネットワークの出力は、上記の学習プロセスで定義したものとよく似てくるはずである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（数学的説明を記述するセル）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">特典：精度が高い上位5名は、10点加点する！</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
